{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Image Classification using AutoGluon\n",
    "\n",
    "In this tutorial, we load images and the corresponding labels into [AutoGluon](https://autogluon.mxnet.io/index.html) and use this data to obtain a neural network that can classify new images. This is different from traditional machine learning where we need to manually define the neural network and then specify the hyperparameters in the training process. Instead, with just a single call to AutoGluon’s fit function, AutoGluon automatically trains many models with different hyperparameter configurations and returns the model that achieved the highest level of accuracy.\n",
    "\n",
    "Note: Please use **GPU** for training. CPU training will lead to an unceasing running script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pathos 0.2.8 requires dill>=0.3.4, but you have dill 0.3.3 which is incompatible.\r\n",
      "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.3 which is incompatible.\r\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.23.25 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -q nvidia-ml-py3==7.352.0\n",
    "! pip install -q torch==1.8.0\n",
    "! pip install -q torchvision==0.9.0\n",
    "! pip install -q d2l==0.16.0\n",
    "! pip install -q numpy==1.19.5\n",
    "! pip install -q setuptools==54.1.1\n",
    "! pip install -q wheel==0.36.2\n",
    "! pip install -q autogluon==0.1.0\n",
    "! pip install -q timm==0.4.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.6.0` and `torch==1.8.0` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "from autogluon.vision import ImagePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use AutoGluon for computer vision task training, we need to organize our data with the following structure:\n",
    "\n",
    "    data/\n",
    "    ├── train/\n",
    "        ├── class1/\n",
    "        ├── class2/\n",
    "        ├── class3/\n",
    "        ├── ...\n",
    "    ├── test/\n",
    "        ├── class1/\n",
    "        ├── class2/\n",
    "        ├── class3/\n",
    "        ├── ...\n",
    "\n",
    "Here each subfolder contains all images that belong to that category, e.g., `class1` contains all images belonging to the first class. We generally recommend at least 100 training images per class for reasonable classification performance, but this might depend on the type of images in your specific use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "For demonstration purposes, we use a subset of the __Shopee-IET__ dataset from [Kaggle](https://www.kaggle.com/competitions). Each image in this data depicts a clothing item and the corresponding label specifies its clothing category. Our subset of the data contains the following possible labels: BabyPants, BabyShirt, womencasualshoes, womenchiffontop.\n",
    "\n",
    "We download the data subset and create training/test dataset folders like below. If you use this on your own dataset, just point it to your training or test folder. Example: `train_dataset = ImagePredictor.Dataset.from_folder('mydataset/train')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.gluoncv/archive/shopee-iet.zip from https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40895/40895 [00:02<00:00, 18951.01KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "├── test/\n",
      "└── train/\n"
     ]
    }
   ],
   "source": [
    "path = 'https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip'\n",
    "train_dataset, _, test_dataset = ImagePredictor.Dataset.from_folders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 image  label\n",
      "0    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "1    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "2    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "3    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "4    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "..                                                 ...    ...\n",
      "795  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "796  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "797  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "798  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "799  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "\n",
      "[800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use AutoGluon to Fit Models\n",
    "\n",
    "Now, let's fit a __classifier__ using AutoGluon [predictor.fit()](https://auto.gluon.ai/stable/tutorials/image_prediction/beginner.html). Within fit, the dataset is __automatically__ split into training and validation sets. The model with the best hyperparameter configuration is selected based on its performance on the __validation set__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluoncv.auto.tasks.image_classification:Randomly split train_data into train[728]/validation[72] splits.\n",
      "INFO:gluoncv.auto.tasks.image_classification:Starting fit without HPO\n",
      "INFO:TorchImageClassificationEstimator:modified configs(<old> != <new>): {\n",
      "INFO:TorchImageClassificationEstimator:root.train.epochs    200 != 15\n",
      "INFO:TorchImageClassificationEstimator:root.train.batch_size 32 != 16\n",
      "INFO:TorchImageClassificationEstimator:root.misc.seed       42 != 564\n",
      "INFO:TorchImageClassificationEstimator:root.img_cls.model   resnet101 != resnet50\n",
      "INFO:TorchImageClassificationEstimator:}\n",
      "INFO:TorchImageClassificationEstimator:Saved config to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/config.yaml\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50_ram-a26f946b.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/resnet50_ram-a26f946b.pth\n",
      "INFO:TorchImageClassificationEstimator:Model resnet50 created, param count:                                         23516228\n",
      "INFO:TorchImageClassificationEstimator:AMP not enabled. Training in float32.\n",
      "INFO:TorchImageClassificationEstimator:Disable EMA as it is not supported for now.\n",
      "INFO:TorchImageClassificationEstimator:Start training from [Epoch 0]\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 0] training: accuracy=0.301389\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 0] speed: 42 samples/sec\ttime cost: 16.638300\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 0] validation: top1=0.402778 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 0] Current best top-1: 0.402778 vs previous -inf, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 1] training: accuracy=0.526389\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 1] speed: 42 samples/sec\ttime cost: 16.415443\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 1] validation: top1=0.833333 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 1] Current best top-1: 0.833333 vs previous 0.402778, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 2] training: accuracy=0.673611\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 2] speed: 42 samples/sec\ttime cost: 16.538302\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 2] validation: top1=0.888889 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 2] Current best top-1: 0.888889 vs previous 0.833333, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 3] training: accuracy=0.727778\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 3] speed: 42 samples/sec\ttime cost: 16.436120\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 3] validation: top1=0.902778 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 3] Current best top-1: 0.902778 vs previous 0.888889, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 4] training: accuracy=0.744444\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 4] speed: 42 samples/sec\ttime cost: 16.481082\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 4] validation: top1=0.888889 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 5] training: accuracy=0.754167\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 5] speed: 42 samples/sec\ttime cost: 16.484461\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 5] validation: top1=0.916667 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 5] Current best top-1: 0.916667 vs previous 0.902778, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 6] training: accuracy=0.786111\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 6] speed: 42 samples/sec\ttime cost: 16.624823\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 6] validation: top1=0.902778 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 7] training: accuracy=0.780556\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 7] speed: 42 samples/sec\ttime cost: 16.518304\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 7] validation: top1=0.916667 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 8] training: accuracy=0.770833\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 8] speed: 42 samples/sec\ttime cost: 16.539604\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 8] validation: top1=0.944444 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 8] Current best top-1: 0.944444 vs previous 0.916667, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 9] training: accuracy=0.795833\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 9] speed: 42 samples/sec\ttime cost: 16.652316\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 9] validation: top1=0.958333 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 9] Current best top-1: 0.958333 vs previous 0.944444, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 10] training: accuracy=0.819444\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 10] speed: 42 samples/sec\ttime cost: 16.510791\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 10] validation: top1=0.944444 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 11] training: accuracy=0.804167\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 11] speed: 42 samples/sec\ttime cost: 16.502366\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 11] validation: top1=0.958333 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 12] training: accuracy=0.831944\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 12] speed: 42 samples/sec\ttime cost: 16.553719\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 12] validation: top1=0.972222 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 12] Current best top-1: 0.972222 vs previous 0.958333, saved to /home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc/.trial_0/best_checkpoint.pkl\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 13] training: accuracy=0.831944\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 13] speed: 42 samples/sec\ttime cost: 16.620514\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 13] validation: top1=0.958333 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 14] training: accuracy=0.854167\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 14] speed: 42 samples/sec\ttime cost: 16.500011\n",
      "INFO:TorchImageClassificationEstimator:[Epoch 14] validation: top1=0.972222 top5=1.000000\n",
      "INFO:TorchImageClassificationEstimator:Applying the state from the best checkpoint...\n",
      "INFO:gluoncv.auto.tasks.image_classification:Finished, total runtime is 281.06 s\n",
      "INFO:gluoncv.auto.tasks.image_classification:{ 'best_config': { 'batch_size': 16,\n",
      "                   'dist_ip_addrs': None,\n",
      "                   'epochs': 15,\n",
      "                   'final_fit': False,\n",
      "                   'gpus': [0],\n",
      "                   'log_dir': '/home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc',\n",
      "                   'lr': 0.01,\n",
      "                   'model': 'resnet50',\n",
      "                   'ngpus_per_trial': 1,\n",
      "                   'nthreads_per_trial': 128,\n",
      "                   'num_trials': 1,\n",
      "                   'num_workers': 4,\n",
      "                   'problem_type': 'multiclass',\n",
      "                   'search_strategy': 'random',\n",
      "                   'seed': 564,\n",
      "                   'time_limits': 600,\n",
      "                   'wall_clock_tick': 1643329357.5302048},\n",
      "  'total_time': 270.5811548233032,\n",
      "  'train_acc': 0.8541666666666666,\n",
      "  'valid_acc': 0.9722222222222222}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.vision.predictor.predictor.ImagePredictor at 0x7f6ae70cc0b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = ImagePredictor()\n",
    "\n",
    "time_limit = 10 * 60 # how long fit() should run (in seconds)\n",
    "predictor.fit(train_dataset,\n",
    "              epochs=10,\n",
    "              time_limit=time_limit,\n",
    "              ngpus_per_trial=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results\n",
    "\n",
    "Autogluon also provides the training results, which can be accessed by calling `predictor.fit_summary()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_acc': 0.8541666666666666,\n",
       " 'valid_acc': 0.9722222222222222,\n",
       " 'total_time': 270.5811548233032,\n",
       " 'best_config': {'model': 'resnet50',\n",
       "  'lr': 0.01,\n",
       "  'num_trials': 1,\n",
       "  'epochs': 15,\n",
       "  'batch_size': 16,\n",
       "  'nthreads_per_trial': 128,\n",
       "  'ngpus_per_trial': 1,\n",
       "  'time_limits': 600,\n",
       "  'search_strategy': 'random',\n",
       "  'dist_ip_addrs': None,\n",
       "  'log_dir': '/home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc',\n",
       "  'num_workers': 4,\n",
       "  'gpus': [0],\n",
       "  'seed': 564,\n",
       "  'final_fit': False,\n",
       "  'wall_clock_tick': 1643329357.5302048,\n",
       "  'problem_type': 'multiclass'},\n",
       " 'fit_history': {'train_acc': 0.8541666666666666,\n",
       "  'valid_acc': 0.9722222222222222,\n",
       "  'total_time': 270.5811548233032,\n",
       "  'best_config': {'model': 'resnet50',\n",
       "   'lr': 0.01,\n",
       "   'num_trials': 1,\n",
       "   'epochs': 15,\n",
       "   'batch_size': 16,\n",
       "   'nthreads_per_trial': 128,\n",
       "   'ngpus_per_trial': 1,\n",
       "   'time_limits': 600,\n",
       "   'search_strategy': 'random',\n",
       "   'dist_ip_addrs': None,\n",
       "   'log_dir': '/home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc',\n",
       "   'num_workers': 4,\n",
       "   'gpus': [0],\n",
       "   'seed': 564,\n",
       "   'final_fit': False,\n",
       "   'wall_clock_tick': 1643329357.5302048,\n",
       "   'problem_type': 'multiclass'}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access certain results from this summary. For example, training and validation accuracies below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.854, val acc: 0.972\n"
     ]
    }
   ],
   "source": [
    "print('Train acc: %.3f, val acc: %.3f' %(fit_result['train_acc'], fit_result['valid_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model and optimum hyperparameters: Learning rate, batch size, epochs can be printed with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'resnet50',\n",
       " 'lr': 0.01,\n",
       " 'num_trials': 1,\n",
       " 'epochs': 15,\n",
       " 'batch_size': 16,\n",
       " 'nthreads_per_trial': 128,\n",
       " 'ngpus_per_trial': 1,\n",
       " 'time_limits': 600,\n",
       " 'search_strategy': 'random',\n",
       " 'dist_ip_addrs': None,\n",
       " 'log_dir': '/home/ec2-user/SageMaker/MLA-CV-Course/notebooks/day_2/960700cc',\n",
       " 'num_workers': 4,\n",
       " 'gpus': [0],\n",
       " 'seed': 564,\n",
       " 'final_fit': False,\n",
       " 'wall_clock_tick': 1643329357.5302048,\n",
       " 'problem_type': 'multiclass'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_result['fit_history']['best_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the predict function to run on different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BabyPants</td>\n",
       "      <td>0.881436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class     score  id\n",
       "0  BabyPants  0.881436   0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = test_dataset.iloc[0]['image']\n",
    "predictor.predict(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               class     score  id  \\\n",
      "0          BabyPants  0.881436   0   \n",
      "1          BabyPants  0.505561   0   \n",
      "2   womencasualshoes  0.488053   2   \n",
      "3          BabyPants  0.409595   0   \n",
      "4          BabyPants  0.906190   0   \n",
      "..               ...       ...  ..   \n",
      "75   womenchiffontop  0.875525   3   \n",
      "76   womenchiffontop  0.794147   3   \n",
      "77   womenchiffontop  0.924260   3   \n",
      "78   womenchiffontop  0.835401   3   \n",
      "79   womenchiffontop  0.762412   3   \n",
      "\n",
      "                                                image  \n",
      "0   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "1   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "2   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "3   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "4   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "..                                                ...  \n",
      "75  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "76  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "77  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "78  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "79  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "pred = predictor.predict(test_dataset)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
